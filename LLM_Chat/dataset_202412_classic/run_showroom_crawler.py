#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ITRI Virtual Showroom Crawler Runner
===================================
å°ˆé–€ç”¨æ–¼çˆ¬å–å·¥ç ”é™¢è™›æ“¬å±•ç¤ºé–“çš„åŸ·è¡Œå™¨
"""

import os
import sys
import subprocess
import time
import argparse
from pathlib import Path
from datetime import datetime

def check_selenium_requirements():
    """æª¢æŸ¥ Selenium ç›¸é—œéœ€æ±‚"""
    print("ğŸ” æª¢æŸ¥ Selenium ç’°å¢ƒ...")
    
    try:
        import selenium
        from selenium import webdriver
        print(f"âœ… Selenium å·²å®‰è£: {selenium.__version__}")
    except ImportError:
        print("âŒ Selenium æœªå®‰è£")
        print("ğŸ’¡ å®‰è£æŒ‡ä»¤: pip install selenium")
        return False
    
    # æª¢æŸ¥ Chrome/Chromium
    try:
        from selenium.webdriver.chrome.options import Options
        chrome_options = Options()
        chrome_options.add_argument('--headless')
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        
        driver = webdriver.Chrome(options=chrome_options)
        driver.quit()
        print("âœ… Chrome WebDriver å¯ç”¨")
        return True
        
    except Exception as e:
        print(f"âš ï¸  Chrome WebDriver å•é¡Œ: {e}")
        print("ğŸ’¡ è«‹ç¢ºä¿å·²å®‰è£ Chrome ç€è¦½å™¨å’Œ chromedriver")
        print("ğŸ’¡ Ubuntu/Debian: sudo apt-get install chromium-browser chromium-chromedriver")
        print("ğŸ’¡ æˆ–ä¸‹è¼‰ ChromeDriver: https://chromedriver.chromium.org/")
        return False

def setup_output_directory():
    """è¨­ç½®è¼¸å‡ºç›®éŒ„"""
    base_dir = Path(__file__).parent
    output_dir = base_dir / "crawled_data" / "showroom"
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # å‰µå»ºæ™‚é–“æˆ³ç›®éŒ„
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    session_dir = output_dir / f"crawl_{timestamp}"
    session_dir.mkdir(exist_ok=True)
    
    return session_dir

def run_showroom_crawler(mode='basic', timeout=None):
    """é‹è¡Œè™›æ“¬å±•ç¤ºé–“çˆ¬èŸ²"""
    
    # æª¢æŸ¥ç’°å¢ƒ
    if mode == 'full' and not check_selenium_requirements():
        print("âš ï¸  Selenium ç’°å¢ƒä¸å®Œæ•´ï¼Œåˆ‡æ›åˆ°åŸºç¤æ¨¡å¼")
        mode = 'basic'
    
    # è¨­ç½®è¼¸å‡ºç›®éŒ„
    session_dir = setup_output_directory()
    
    # åˆ‡æ›åˆ°çˆ¬èŸ²ç›®éŒ„
    crawler_dir = Path(__file__).parent / "itri_scrapy_crawler"
    os.chdir(crawler_dir)
    
    # æº–å‚™çˆ¬å–å‘½ä»¤
    cmd = [
        sys.executable, "-m", "scrapy", "crawl", "itri_showroom",
        "-L", "INFO",
        "-o", f"{session_dir}/showroom_data.json",
    ]
    
    # æ ¹æ“šæ¨¡å¼èª¿æ•´è¨­ç½®
    if mode == 'basic':
        cmd.extend([
            "-s", "DOWNLOAD_DELAY=2",
            "-s", "CONCURRENT_REQUESTS=2"
        ])
    elif mode == 'full':
        cmd.extend([
            "-s", "DOWNLOAD_DELAY=5",
            "-s", "CONCURRENT_REQUESTS=1"
        ])
    
    if timeout:
        cmd.extend(["-s", f"CLOSESPIDER_TIMEOUT={timeout}"])
    
    print("ğŸš€ å•Ÿå‹• ITRI è™›æ“¬å±•ç¤ºé–“çˆ¬èŸ²")
    print("=" * 60)
    print(f"ğŸ“‚ å·¥ä½œç›®éŒ„: {crawler_dir}")
    print(f"ğŸ’¾ è¼¸å‡ºç›®éŒ„: {session_dir}")
    print(f"ğŸ”§ çˆ¬å–æ¨¡å¼: {mode}")
    print(f"ğŸ”§ åŸ·è¡Œå‘½ä»¤: {' '.join(cmd)}")
    print("=" * 60)
    
    # åŸ·è¡Œçˆ¬èŸ²
    start_time = time.time()
    
    try:
        process = subprocess.Popen(
            cmd,
            stdout=subprocess.PIPE,
            stderr=subprocess.STDOUT,
            text=True,
            bufsize=1,
            universal_newlines=True
        )
        
        # å¯¦æ™‚é¡¯ç¤ºè¼¸å‡º
        for line in iter(process.stdout.readline, ''):
            print(line.rstrip())
        
        process.wait()
        
        end_time = time.time()
        duration = end_time - start_time
        
        print("\n" + "=" * 60)
        if process.returncode == 0:
            print("âœ… è™›æ“¬å±•ç¤ºé–“çˆ¬èŸ²å®Œæˆï¼")
            
            # æª¢æŸ¥è¼¸å‡ºæ–‡ä»¶
            output_file = session_dir / "showroom_data.json"
            if output_file.exists():
                file_size = output_file.stat().st_size
                print(f"ğŸ“Š è¼¸å‡ºæ–‡ä»¶: {output_file}")
                print(f"ğŸ“ æ–‡ä»¶å¤§å°: {file_size:,} bytes")
                
                # ç°¡å–®çµ±è¨ˆ
                try:
                    import json
                    with open(output_file, 'r', encoding='utf-8') as f:
                        data = json.load(f)
                    
                    if isinstance(data, list):
                        print(f"ğŸ“ˆ çˆ¬å–é …ç›®æ•¸: {len(data)}")
                        
                        # çµ±è¨ˆå…§å®¹é¡å‹
                        content_types = {}
                        for item in data:
                            ct = item.get('content_type', 'unknown')
                            content_types[ct] = content_types.get(ct, 0) + 1
                        
                        print("ğŸ“‹ å…§å®¹é¡å‹åˆ†å¸ƒ:")
                        for ct, count in content_types.items():
                            print(f"   {ct}: {count}")
                            
                except Exception as e:
                    print(f"âš ï¸  ç„¡æ³•è§£æè¼¸å‡ºæ–‡ä»¶: {e}")
            
        else:
            print(f"âŒ çˆ¬èŸ²å¤±æ•—ï¼Œé€€å‡ºä»£ç¢¼: {process.returncode}")
        
        print(f"â±ï¸  åŸ·è¡Œæ™‚é–“: {duration:.1f} ç§’")
        print("=" * 60)
        
        return process.returncode == 0, session_dir
        
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ¶ä¸­æ–·çˆ¬å–")
        process.terminate()
        process.wait()
        return False, session_dir
        
    except Exception as e:
        print(f"\nâŒ åŸ·è¡ŒéŒ¯èª¤: {e}")
        return False, session_dir

def main():
    """ä¸»å‡½æ•¸"""
    parser = argparse.ArgumentParser(
        description='ITRI Virtual Showroom Crawler',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¯„ä¾‹:
  # åŸºç¤çˆ¬å– (ä¸ä½¿ç”¨ Selenium)
  python run_showroom_crawler.py --mode basic
  
  # å®Œæ•´çˆ¬å– (ä½¿ç”¨ Selenium è™•ç† JavaScript)
  python run_showroom_crawler.py --mode full
  
  # é™æ™‚çˆ¬å–
  python run_showroom_crawler.py --timeout 300
        """
    )
    
    parser.add_argument('--mode', 
                       choices=['basic', 'full'],
                       default='basic',
                       help='çˆ¬å–æ¨¡å¼ (basic: åŸºç¤HTML, full: åŒ…å«JavaScript)')
    
    parser.add_argument('--timeout',
                       type=int,
                       help='çˆ¬å–è¶…æ™‚æ™‚é–“ (ç§’)')
    
    parser.add_argument('--check-env',
                       action='store_true',
                       help='åƒ…æª¢æŸ¥ç’°å¢ƒï¼Œä¸åŸ·è¡Œçˆ¬å–')
    
    args = parser.parse_args()
    
    print("ğŸ›ï¸  ITRI è™›æ“¬å±•ç¤ºé–“çˆ¬èŸ²")
    print("=" * 40)
    
    if args.check_env:
        print("ğŸ” ç’°å¢ƒæª¢æŸ¥æ¨¡å¼")
        selenium_ok = check_selenium_requirements()
        if selenium_ok:
            print("âœ… ç’°å¢ƒæª¢æŸ¥å®Œæˆï¼Œå¯ä»¥ä½¿ç”¨å®Œæ•´æ¨¡å¼")
        else:
            print("âš ï¸  å»ºè­°ä½¿ç”¨åŸºç¤æ¨¡å¼")
        return
    
    # åŸ·è¡Œçˆ¬å–
    success, output_dir = run_showroom_crawler(
        mode=args.mode,
        timeout=args.timeout
    )
    
    if success:
        print(f"\nğŸ‰ çˆ¬å–æˆåŠŸå®Œæˆï¼")
        print(f"ğŸ“ æ•¸æ“šä¿å­˜åœ¨: {output_dir}")
        print(f"\nğŸ’¡ å¾ŒçºŒæ­¥é©Ÿ:")
        print(f"   1. æª¢æŸ¥æ•¸æ“š: ls -la {output_dir}")
        print(f"   2. æŸ¥çœ‹å…§å®¹: head -20 {output_dir}/showroom_data.json")
        print(f"   3. åˆ†ææ•¸æ“š: python analyze_showroom_data.py {output_dir}")
    else:
        print(f"\nâŒ çˆ¬å–æœªæˆåŠŸå®Œæˆ")
        print(f"ğŸ“ éƒ¨åˆ†æ•¸æ“šå¯èƒ½ä¿å­˜åœ¨: {output_dir}")

if __name__ == "__main__":
    main()
