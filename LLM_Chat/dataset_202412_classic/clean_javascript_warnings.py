#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
JavaScript Warning Cleaner for ITRI Crawled Data
================================================
æ¸…ç†å·²çˆ¬å–æ•¸æ“šä¸­çš„ JavaScript è­¦å‘Šè¨Šæ¯
"""

import json
import re
import os
from pathlib import Path
from datetime import datetime

def clean_javascript_warnings(text):
    """Remove JavaScript warning messages from text"""
    if not text:
        return text
        
    # JavaScript warning and code patterns
    js_warning_patterns = [
        r'ã€æ‚¨çš„ç€è¦½å™¨ä¸æ”¯æ´JavaScriptåŠŸèƒ½ï¼Œè‹¥ç¶²é åŠŸèƒ½ç„¡æ³•æ­£å¸¸ä½¿ç”¨æ™‚ï¼Œè«‹é–‹å•Ÿç€è¦½å™¨JavaScriptç‹€æ…‹ã€\s*',
        r'Your browser does not support JavaScript.*?please enable JavaScript\s*',
        r'è«‹é–‹å•Ÿç€è¦½å™¨JavaScriptåŠŸèƒ½.*?\s*',
        r'//\s*\(function\s*\([^)]*\)\s*\{.*?\}\)\s*\([^)]*\)\s*;?\s*',  # GTM JavaScript code
        r'function\s*\([^)]*\)\s*\{[^}]*gtm[^}]*\}',  # GTM function blocks
    ]
    
    cleaned_text = text
    for pattern in js_warning_patterns:
        cleaned_text = re.sub(pattern, '', cleaned_text, flags=re.IGNORECASE | re.MULTILINE)
    
    # Clean up excessive whitespace
    cleaned_text = re.sub(r'\s+', ' ', cleaned_text).strip()
    
    return cleaned_text

def clean_json_file(file_path):
    """Clean JavaScript warnings from a JSON file"""
    print(f"ğŸ§¹ æ¸…ç†æ–‡ä»¶: {file_path}")
    
    try:
        # Read the JSON file
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        if not isinstance(data, list):
            print(f"âš ï¸  è·³é: {file_path} (ä¸æ˜¯æ•¸çµ„æ ¼å¼)")
            return 0
        
        cleaned_count = 0
        
        # Clean each item
        for item in data:
            if isinstance(item, dict):
                # Clean content field
                if 'content' in item and item['content']:
                    original_content = item['content']
                    cleaned_content = clean_javascript_warnings(original_content)
                    if cleaned_content != original_content:
                        item['content'] = cleaned_content
                        cleaned_count += 1
                
                # Clean summary field
                if 'summary' in item and item['summary']:
                    original_summary = item['summary']
                    cleaned_summary = clean_javascript_warnings(original_summary)
                    if cleaned_summary != original_summary:
                        item['summary'] = cleaned_summary
                
                # Clean title field (less likely but just in case)
                if 'title' in item and item['title']:
                    original_title = item['title']
                    cleaned_title = clean_javascript_warnings(original_title)
                    if cleaned_title != original_title:
                        item['title'] = cleaned_title
        
        # Create backup
        backup_path = f"{file_path}.backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        os.rename(file_path, backup_path)
        print(f"ğŸ“¦ å‚™ä»½å·²å‰µå»º: {backup_path}")
        
        # Write cleaned data
        with open(file_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… å·²æ¸…ç† {cleaned_count} å€‹é …ç›®")
        return cleaned_count
        
    except Exception as e:
        print(f"âŒ æ¸…ç†å¤±æ•—: {e}")
        return 0

def main():
    """Main function"""
    print("ğŸ§¹ JavaScript è­¦å‘Šæ¸…ç†å·¥å…·")
    print("=" * 50)
    
    # Find all JSON files in crawled_data directories
    base_dir = Path(__file__).parent
    json_files = []
    
    # Search in main crawled_data
    crawled_data_dir = base_dir / "crawled_data"
    if crawled_data_dir.exists():
        json_files.extend(crawled_data_dir.rglob("*.json"))
    
    # Search in itri_scrapy_crawler/crawled_data
    itri_crawled_dir = base_dir / "itri_scrapy_crawler" / "crawled_data"
    if itri_crawled_dir.exists():
        json_files.extend(itri_crawled_dir.rglob("*.json"))
    
    if not json_files:
        print("ğŸ“‚ æœªæ‰¾åˆ°ä»»ä½• JSON æ–‡ä»¶")
        return
    
    print(f"ğŸ“ æ‰¾åˆ° {len(json_files)} å€‹ JSON æ–‡ä»¶")
    print()
    
    total_cleaned = 0
    
    for json_file in json_files:
        # Skip statistics files
        if 'statistics' in json_file.name.lower():
            print(f"â­ï¸  è·³éçµ±è¨ˆæ–‡ä»¶: {json_file}")
            continue
            
        cleaned_count = clean_json_file(json_file)
        total_cleaned += cleaned_count
        print()
    
    print("=" * 50)
    print(f"ğŸ‰ æ¸…ç†å®Œæˆï¼ç¸½å…±æ¸…ç†äº† {total_cleaned} å€‹é …ç›®")
    print()
    print("ğŸ’¡ æç¤º:")
    print("  - åŸå§‹æ–‡ä»¶å·²å‚™ä»½ (.backup_* æ–‡ä»¶)")
    print("  - æ–°çš„çˆ¬å–æ•¸æ“šå°‡è‡ªå‹•æ¸…ç† JavaScript è­¦å‘Š")
    print("  - å¦‚éœ€é‚„åŸï¼Œè«‹é‡å‘½åå‚™ä»½æ–‡ä»¶")

if __name__ == "__main__":
    main()
