#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ITRI RAG Database Builder - Step 2: Build Vector Database
è®€å–çˆ¬å–çš„ JSON è³‡æ–™ï¼Œé€²è¡Œ Chunking èˆ‡ Embeddingï¼Œä¸¦å­˜å…¥ ChromaDB
"""

import json
import os
from pathlib import Path
from datetime import datetime

try:
    from langchain_text_splitters import RecursiveCharacterTextSplitter
    from langchain_community.embeddings import OllamaEmbeddings
    from langchain_community.vectorstores import Chroma
    from langchain_core.documents import Document
except ImportError as e:
    print("âŒ ç¼ºå°‘å¿…è¦çš„å¥—ä»¶ï¼Œè«‹å…ˆå®‰è£ï¼š")
    print("   pip install langchain langchain-community langchain-huggingface chromadb")
    print(f"\néŒ¯èª¤è©³æƒ…: {e}")
    exit(1)

# --- è¨­å®š ---
INPUT_FILE = os.path.join("crawled_data", "itri_raw_data.json")
CHROMA_PATH = "./chroma_db_itri"
OLLAMA_EMBED_MODEL = "bge-m3"  # æˆ–ä½¿ç”¨ "nomic-embed-text"
OLLAMA_BASE_URL = "http://localhost:11435"

# Chunking åƒæ•¸
CHUNK_SIZE = 500      # æ¯å€‹å€å¡Šçš„å¤§å°ï¼ˆå­—å…ƒæ•¸ï¼‰
CHUNK_OVERLAP = 100   # é‡ç–Šå€å¡Šå¤§å°ï¼Œç¢ºä¿ä¸Šä¸‹æ–‡ä¸ä¸­æ–·


def load_and_chunk_data():
    """è¼‰å…¥åŸå§‹è³‡æ–™ä¸¦é€²è¡Œåˆ‡ç‰‡"""
    if not os.path.exists(INPUT_FILE):
        print(f"âŒ æ‰¾ä¸åˆ°è³‡æ–™æª”: {INPUT_FILE}")
        print("   è«‹å…ˆåŸ·è¡Œ 1_crawl_data.py é€²è¡Œè³‡æ–™çˆ¬å–ï¼")
        return []

    print("=" * 60)
    print("ğŸ“š ITRI RAG Database Builder - Step 2: Build Vector Database")
    print("=" * 60)
    
    print(f"\n1ï¸âƒ£  è¼‰å…¥åŸå§‹è³‡æ–™...")
    print(f"   ğŸ“ æª”æ¡ˆ: {INPUT_FILE}")
    
    try:
        with open(INPUT_FILE, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except json.JSONDecodeError as e:
        print(f"âŒ JSON è§£æéŒ¯èª¤: {e}")
        return []
    except Exception as e:
        print(f"âŒ è®€å–æª”æ¡ˆéŒ¯èª¤: {e}")
        return []

    if not data:
        print("âš ï¸  è³‡æ–™æª”ç‚ºç©ºï¼Œè«‹æª¢æŸ¥çˆ¬èŸ²æ˜¯å¦æˆåŠŸåŸ·è¡Œ")
        return []

    print(f"   âœ… å…±è¼‰å…¥ {len(data)} ç¯‡æ–‡ç« ")

    # å°‡ JSON è½‰ç‚º LangChain Document ç‰©ä»¶
    print(f"\n2ï¸âƒ£  è½‰æ›ç‚º Document ç‰©ä»¶...")
    documents = []
    for i, item in enumerate(data):
        doc = Document(
            page_content=item.get('content', ''),
            metadata={
                "source": item.get('source', 'Unknown'),
                "title": item.get('title', 'Untitled'),
                "url": item.get('url', ''),
                "hierarchy": item.get('hierarchy', ''),
                "language": item.get('language', 'zh-tw'),
                "crawled_at": item.get('crawled_at', ''),
                "depth": item.get('depth', 0),
                "doc_id": i  # æ·»åŠ æ–‡ä»¶ ID
            }
        )
        documents.append(doc)
    
    print(f"   âœ… è½‰æ›å®Œæˆï¼Œå…± {len(documents)} å€‹æ–‡ä»¶")

    # åŸ·è¡Œåˆ‡ç‰‡ (Chunking)
    print(f"\n3ï¸âƒ£  åŸ·è¡Œåˆ‡ç‰‡ (Chunking)...")
    print(f"   ğŸ“ Chunk Size: {CHUNK_SIZE} å­—å…ƒ")
    print(f"   ğŸ”— Chunk Overlap: {CHUNK_OVERLAP} å­—å…ƒ")
    
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=CHUNK_SIZE,
        chunk_overlap=CHUNK_OVERLAP,
        separators=["\n\n", "\n", "ã€‚", "ï¼", "ï¼Ÿ", ".", "!", "?", " ", ""]
    )
    
    chunks = text_splitter.split_documents(documents)
    print(f"   âœ… åˆ‡ç‰‡å®Œæˆï¼Œå…±ç”Ÿæˆ {len(chunks)} å€‹çŸ¥è­˜å€å¡Š")
    
    # é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
    if chunks:
        avg_chunk_size = sum(len(chunk.page_content) for chunk in chunks) / len(chunks)
        print(f"   ğŸ“Š å¹³å‡å€å¡Šå¤§å°: {avg_chunk_size:.0f} å­—å…ƒ")
    
    return chunks


def save_to_chroma(chunks):
    """å°‡åˆ‡ç‰‡å¾Œçš„è³‡æ–™å‘é‡åŒ–ä¸¦å­˜å…¥ ChromaDB"""
    if not chunks:
        print("âŒ æ²’æœ‰è³‡æ–™å¯ä»¥å„²å­˜")
        return False
    
    print(f"\n4ï¸âƒ£  å‘é‡åŒ–ä¸¦å­˜å…¥ ChromaDB...")
    print(f"   ğŸ¤– Embedding Model: {OLLAMA_EMBED_MODEL}")
    print(f"   ğŸŒ Ollama URL: {OLLAMA_BASE_URL}")
    print(f"   ğŸ’¾ è³‡æ–™åº«è·¯å¾‘: {CHROMA_PATH}")
    
    # æª¢æŸ¥ Ollama æ˜¯å¦å¯ç”¨
    try:
        import requests
        response = requests.get(f"{OLLAMA_BASE_URL}/api/tags", timeout=5)
        if response.status_code != 200:
            print(f"âš ï¸  è­¦å‘Š: ç„¡æ³•é€£æ¥åˆ° Ollama ({OLLAMA_BASE_URL})")
            print("   è«‹ç¢ºèª Ollama å·²å•Ÿå‹•ï¼Œä¸¦å·²ä¸‹è¼‰æ¨¡å‹:")
            print(f"   ollama pull {OLLAMA_EMBED_MODEL}")
    except Exception as e:
        print(f"âš ï¸  è­¦å‘Š: ç„¡æ³•é€£æ¥åˆ° Ollama: {e}")
        print("   è«‹ç¢ºèª Ollama å·²å•Ÿå‹•")
    
    try:
        # å»ºç«‹ Embedding å‡½æ•¸
        print(f"\n   ğŸ”„ åˆå§‹åŒ– Embedding æ¨¡å‹...")
        embedding_function = OllamaEmbeddings(
            model=OLLAMA_EMBED_MODEL,
            base_url=OLLAMA_BASE_URL
        )
        
        # æ¸¬è©¦ Embeddingï¼ˆç¢ºä¿æ¨¡å‹å¯ç”¨ï¼‰
        print(f"   ğŸ§ª æ¸¬è©¦ Embedding...")
        test_embedding = embedding_function.embed_query("æ¸¬è©¦")
        print(f"   âœ… Embedding ç¶­åº¦: {len(test_embedding)}")
        
        # å¦‚æœè³‡æ–™åº«å·²å­˜åœ¨ï¼Œå…ˆåˆªé™¤èˆŠçš„
        if os.path.exists(CHROMA_PATH):
            print(f"   ğŸ—‘ï¸  åˆªé™¤èˆŠè³‡æ–™åº«...")
            import shutil
            shutil.rmtree(CHROMA_PATH)
        
        # å»ºç«‹ä¸¦æŒä¹…åŒ–è³‡æ–™åº«
        print(f"\n   ğŸ’¾ é–‹å§‹å‘é‡åŒ–ä¸¦å„²å­˜ï¼ˆé€™å¯èƒ½éœ€è¦ä¸€äº›æ™‚é–“ï¼‰...")
        print(f"   â³ è™•ç† {len(chunks)} å€‹å€å¡Š...")
        
        db = Chroma.from_documents(
            documents=chunks,
            embedding=embedding_function,
            persist_directory=CHROMA_PATH
        )
        
        # é©—è­‰è³‡æ–™åº«
        collection_count = db._collection.count()
        print(f"\n   âœ… è³‡æ–™åº«å»ºç½®å®Œæˆï¼")
        print(f"   ğŸ“Š å„²å­˜çš„å‘é‡æ•¸é‡: {collection_count}")
        print(f"   ğŸ’¾ è³‡æ–™åº«ä½ç½®: {os.path.abspath(CHROMA_PATH)}")
        
        return True
        
    except Exception as e:
        print(f"\nâŒ å»ºç«‹è³‡æ–™åº«æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»å‡½æ•¸"""
    chunks = load_and_chunk_data()
    if chunks:
        success = save_to_chroma(chunks)
        if success:
            print("\n" + "=" * 60)
            print("ğŸ‰ RAG è³‡æ–™åº«å»ºç½®æˆåŠŸï¼")
            print("=" * 60)
            print(f"\nä¸‹ä¸€æ­¥ï¼šåŸ·è¡Œ 3_chat_demo.py é–‹å§‹å°è©±æ¸¬è©¦")
            print("=" * 60)
        else:
            print("\n" + "=" * 60)
            print("âŒ RAG è³‡æ–™åº«å»ºç½®å¤±æ•—")
            print("=" * 60)
    else:
        print("\n" + "=" * 60)
        print("âŒ ç„¡æ³•è¼‰å…¥è³‡æ–™ï¼Œè«‹æª¢æŸ¥è¼¸å…¥æª”æ¡ˆ")
        print("=" * 60)


if __name__ == "__main__":
    main()







